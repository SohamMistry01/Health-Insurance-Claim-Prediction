{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health Insurance Claim Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Medicalpremium.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Diabetes  BloodPressureProblems  AnyTransplants  AnyChronicDiseases  \\\n",
       "0   45         0                      0               0                   0   \n",
       "1   60         1                      0               0                   0   \n",
       "2   36         1                      1               0                   0   \n",
       "3   52         1                      1               0                   1   \n",
       "4   38         0                      0               0                   1   \n",
       "\n",
       "   Height  Weight  KnownAllergies  HistoryOfCancerInFamily  \\\n",
       "0     155      57               0                        0   \n",
       "1     180      73               0                        0   \n",
       "2     158      59               0                        0   \n",
       "3     183      93               0                        0   \n",
       "4     166      88               0                        0   \n",
       "\n",
       "   NumberOfMajorSurgeries  PremiumPrice  \n",
       "0                       0         25000  \n",
       "1                       0         29000  \n",
       "2                       1         23000  \n",
       "3                       2         28000  \n",
       "4                       1         23000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extracting BMI Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BMI'] = df['Weight'] / ( (df['Height']/100)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>23.725286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000</td>\n",
       "      <td>22.530864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>23.634033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28000</td>\n",
       "      <td>27.770313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>31.934969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Diabetes  BloodPressureProblems  AnyTransplants  AnyChronicDiseases  \\\n",
       "0   45         0                      0               0                   0   \n",
       "1   60         1                      0               0                   0   \n",
       "2   36         1                      1               0                   0   \n",
       "3   52         1                      1               0                   1   \n",
       "4   38         0                      0               0                   1   \n",
       "\n",
       "   Height  Weight  KnownAllergies  HistoryOfCancerInFamily  \\\n",
       "0     155      57               0                        0   \n",
       "1     180      73               0                        0   \n",
       "2     158      59               0                        0   \n",
       "3     183      93               0                        0   \n",
       "4     166      88               0                        0   \n",
       "\n",
       "   NumberOfMajorSurgeries  PremiumPrice        BMI  \n",
       "0                       0         25000  23.725286  \n",
       "1                       0         29000  22.530864  \n",
       "2                       1         23000  23.634033  \n",
       "3                       2         28000  27.770313  \n",
       "4                       1         23000  31.934969  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.745436</td>\n",
       "      <td>0.419878</td>\n",
       "      <td>0.468560</td>\n",
       "      <td>0.055781</td>\n",
       "      <td>0.180527</td>\n",
       "      <td>168.182556</td>\n",
       "      <td>76.950304</td>\n",
       "      <td>0.215010</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.667343</td>\n",
       "      <td>24336.713996</td>\n",
       "      <td>27.460709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.963371</td>\n",
       "      <td>0.493789</td>\n",
       "      <td>0.499264</td>\n",
       "      <td>0.229615</td>\n",
       "      <td>0.384821</td>\n",
       "      <td>10.098155</td>\n",
       "      <td>14.265096</td>\n",
       "      <td>0.411038</td>\n",
       "      <td>0.322353</td>\n",
       "      <td>0.749205</td>\n",
       "      <td>6248.184382</td>\n",
       "      <td>5.878671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15.156281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>23.393392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>27.156602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28000.000000</td>\n",
       "      <td>30.759870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age    Diabetes  BloodPressureProblems  AnyTransplants  \\\n",
       "count  986.000000  986.000000             986.000000      986.000000   \n",
       "mean    41.745436    0.419878               0.468560        0.055781   \n",
       "std     13.963371    0.493789               0.499264        0.229615   \n",
       "min     18.000000    0.000000               0.000000        0.000000   \n",
       "25%     30.000000    0.000000               0.000000        0.000000   \n",
       "50%     42.000000    0.000000               0.000000        0.000000   \n",
       "75%     53.000000    1.000000               1.000000        0.000000   \n",
       "max     66.000000    1.000000               1.000000        1.000000   \n",
       "\n",
       "       AnyChronicDiseases      Height      Weight  KnownAllergies  \\\n",
       "count          986.000000  986.000000  986.000000      986.000000   \n",
       "mean             0.180527  168.182556   76.950304        0.215010   \n",
       "std              0.384821   10.098155   14.265096        0.411038   \n",
       "min              0.000000  145.000000   51.000000        0.000000   \n",
       "25%              0.000000  161.000000   67.000000        0.000000   \n",
       "50%              0.000000  168.000000   75.000000        0.000000   \n",
       "75%              0.000000  176.000000   87.000000        0.000000   \n",
       "max              1.000000  188.000000  132.000000        1.000000   \n",
       "\n",
       "       HistoryOfCancerInFamily  NumberOfMajorSurgeries  PremiumPrice  \\\n",
       "count               986.000000              986.000000    986.000000   \n",
       "mean                  0.117647                0.667343  24336.713996   \n",
       "std                   0.322353                0.749205   6248.184382   \n",
       "min                   0.000000                0.000000  15000.000000   \n",
       "25%                   0.000000                0.000000  21000.000000   \n",
       "50%                   0.000000                1.000000  23000.000000   \n",
       "75%                   0.000000                1.000000  28000.000000   \n",
       "max                   1.000000                3.000000  40000.000000   \n",
       "\n",
       "              BMI  \n",
       "count  986.000000  \n",
       "mean    27.460709  \n",
       "std      5.878671  \n",
       "min     15.156281  \n",
       "25%     23.393392  \n",
       "50%     27.156602  \n",
       "75%     30.759870  \n",
       "max     50.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <th>AnyTransplants</th>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>KnownAllergies</th>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <th>PremiumPrice</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210908</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>-0.008549</td>\n",
       "      <td>0.051072</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>-0.018590</td>\n",
       "      <td>-0.024416</td>\n",
       "      <td>-0.027623</td>\n",
       "      <td>0.429181</td>\n",
       "      <td>0.697540</td>\n",
       "      <td>-0.042027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diabetes</th>\n",
       "      <td>0.210908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127727</td>\n",
       "      <td>-0.036652</td>\n",
       "      <td>-0.089428</td>\n",
       "      <td>-0.003783</td>\n",
       "      <td>-0.024563</td>\n",
       "      <td>-0.080102</td>\n",
       "      <td>-0.055527</td>\n",
       "      <td>0.122722</td>\n",
       "      <td>0.076209</td>\n",
       "      <td>-0.022913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressureProblems</th>\n",
       "      <td>0.244888</td>\n",
       "      <td>0.127727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024538</td>\n",
       "      <td>0.045424</td>\n",
       "      <td>-0.037926</td>\n",
       "      <td>-0.061016</td>\n",
       "      <td>-0.011550</td>\n",
       "      <td>0.048239</td>\n",
       "      <td>0.251568</td>\n",
       "      <td>0.167097</td>\n",
       "      <td>-0.038028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyTransplants</th>\n",
       "      <td>-0.008549</td>\n",
       "      <td>-0.036652</td>\n",
       "      <td>-0.024538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>-0.031543</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>-0.020171</td>\n",
       "      <td>-0.004154</td>\n",
       "      <td>0.289056</td>\n",
       "      <td>0.023508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyChronicDiseases</th>\n",
       "      <td>0.051072</td>\n",
       "      <td>-0.089428</td>\n",
       "      <td>0.045424</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>-0.033318</td>\n",
       "      <td>-0.027418</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>0.208610</td>\n",
       "      <td>-0.056980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.039879</td>\n",
       "      <td>-0.003783</td>\n",
       "      <td>-0.037926</td>\n",
       "      <td>-0.031543</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>-0.010200</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.037289</td>\n",
       "      <td>0.026910</td>\n",
       "      <td>-0.504947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>-0.018590</td>\n",
       "      <td>-0.024563</td>\n",
       "      <td>-0.061016</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>-0.033318</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037492</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>0.141507</td>\n",
       "      <td>0.820679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KnownAllergies</th>\n",
       "      <td>-0.024416</td>\n",
       "      <td>-0.080102</td>\n",
       "      <td>-0.011550</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>-0.027418</td>\n",
       "      <td>-0.010200</td>\n",
       "      <td>0.037492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115383</td>\n",
       "      <td>0.103923</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.040437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistoryOfCancerInFamily</th>\n",
       "      <td>-0.027623</td>\n",
       "      <td>-0.055527</td>\n",
       "      <td>0.048239</td>\n",
       "      <td>-0.020171</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.115383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212657</td>\n",
       "      <td>0.083139</td>\n",
       "      <td>0.002390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumberOfMajorSurgeries</th>\n",
       "      <td>0.429181</td>\n",
       "      <td>0.122722</td>\n",
       "      <td>0.251568</td>\n",
       "      <td>-0.004154</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>0.037289</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>0.103923</td>\n",
       "      <td>0.212657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>-0.027225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PremiumPrice</th>\n",
       "      <td>0.697540</td>\n",
       "      <td>0.076209</td>\n",
       "      <td>0.167097</td>\n",
       "      <td>0.289056</td>\n",
       "      <td>0.208610</td>\n",
       "      <td>0.026910</td>\n",
       "      <td>0.141507</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.083139</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>-0.042027</td>\n",
       "      <td>-0.022913</td>\n",
       "      <td>-0.038028</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>-0.056980</td>\n",
       "      <td>-0.504947</td>\n",
       "      <td>0.820679</td>\n",
       "      <td>0.040437</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>-0.027225</td>\n",
       "      <td>0.103812</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Age  Diabetes  BloodPressureProblems  \\\n",
       "Age                      1.000000  0.210908               0.244888   \n",
       "Diabetes                 0.210908  1.000000               0.127727   \n",
       "BloodPressureProblems    0.244888  0.127727               1.000000   \n",
       "AnyTransplants          -0.008549 -0.036652              -0.024538   \n",
       "AnyChronicDiseases       0.051072 -0.089428               0.045424   \n",
       "Height                   0.039879 -0.003783              -0.037926   \n",
       "Weight                  -0.018590 -0.024563              -0.061016   \n",
       "KnownAllergies          -0.024416 -0.080102              -0.011550   \n",
       "HistoryOfCancerInFamily -0.027623 -0.055527               0.048239   \n",
       "NumberOfMajorSurgeries   0.429181  0.122722               0.251568   \n",
       "PremiumPrice             0.697540  0.076209               0.167097   \n",
       "BMI                     -0.042027 -0.022913              -0.038028   \n",
       "\n",
       "                         AnyTransplants  AnyChronicDiseases    Height  \\\n",
       "Age                           -0.008549            0.051072  0.039879   \n",
       "Diabetes                      -0.036652           -0.089428 -0.003783   \n",
       "BloodPressureProblems         -0.024538            0.045424 -0.037926   \n",
       "AnyTransplants                 1.000000            0.035285 -0.031543   \n",
       "AnyChronicDiseases             0.035285            1.000000  0.047419   \n",
       "Height                        -0.031543            0.047419  1.000000   \n",
       "Weight                         0.002087           -0.033318  0.066946   \n",
       "KnownAllergies                 0.001876           -0.027418 -0.010200   \n",
       "HistoryOfCancerInFamily       -0.020171            0.008666  0.010549   \n",
       "NumberOfMajorSurgeries        -0.004154            0.014835  0.037289   \n",
       "PremiumPrice                   0.289056            0.208610  0.026910   \n",
       "BMI                            0.023508           -0.056980 -0.504947   \n",
       "\n",
       "                           Weight  KnownAllergies  HistoryOfCancerInFamily  \\\n",
       "Age                     -0.018590       -0.024416                -0.027623   \n",
       "Diabetes                -0.024563       -0.080102                -0.055527   \n",
       "BloodPressureProblems   -0.061016       -0.011550                 0.048239   \n",
       "AnyTransplants           0.002087        0.001876                -0.020171   \n",
       "AnyChronicDiseases      -0.033318       -0.027418                 0.008666   \n",
       "Height                   0.066946       -0.010200                 0.010549   \n",
       "Weight                   1.000000        0.037492                 0.003481   \n",
       "KnownAllergies           0.037492        1.000000                 0.115383   \n",
       "HistoryOfCancerInFamily  0.003481        0.115383                 1.000000   \n",
       "NumberOfMajorSurgeries  -0.006108        0.103923                 0.212657   \n",
       "PremiumPrice             0.141507        0.012103                 0.083139   \n",
       "BMI                      0.820679        0.040437                 0.002390   \n",
       "\n",
       "                         NumberOfMajorSurgeries  PremiumPrice       BMI  \n",
       "Age                                    0.429181      0.697540 -0.042027  \n",
       "Diabetes                               0.122722      0.076209 -0.022913  \n",
       "BloodPressureProblems                  0.251568      0.167097 -0.038028  \n",
       "AnyTransplants                        -0.004154      0.289056  0.023508  \n",
       "AnyChronicDiseases                     0.014835      0.208610 -0.056980  \n",
       "Height                                 0.037289      0.026910 -0.504947  \n",
       "Weight                                -0.006108      0.141507  0.820679  \n",
       "KnownAllergies                         0.103923      0.012103  0.040437  \n",
       "HistoryOfCancerInFamily                0.212657      0.083139  0.002390  \n",
       "NumberOfMajorSurgeries                 1.000000      0.264250 -0.027225  \n",
       "PremiumPrice                           0.264250      1.000000  0.103812  \n",
       "BMI                                   -0.027225      0.103812  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['PremiumPrice'])  # Independent features\n",
    "y = df['PremiumPrice']  # Dependent variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluating Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function to Evaluate Model\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 112.4317\n",
      "- Mean Absolute Error: 71.2485\n",
      "- R2 Score: 0.9997\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 2386.0513\n",
      "- Mean Absolute Error: 1280.8626\n",
      "- R2 Score: 0.8665\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2030.0182\n",
      "- Mean Absolute Error: 1177.8247\n",
      "- R2 Score: 0.8917\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 2372.9243\n",
      "- Mean Absolute Error: 1519.1369\n",
      "- R2 Score: 0.8680\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1150.3812\n",
      "- Mean Absolute Error: 464.6954\n",
      "- R2 Score: 0.9652\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 2069.4677\n",
      "- Mean Absolute Error: 953.4848\n",
      "- R2 Score: 0.8996\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Beginning Model Training\n",
    "models = {\n",
    "    \"XGBoost Regressor\": XGBRegressor(),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Hyperparameter Tuning using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-04 20:04:20,141] A new study created in memory with name: no-name-02ebcf10-b7a0-4c05-97d5-37a08a2c5601\n",
      "[I 2025-04-04 20:04:23,413] Trial 2 finished with value: -10912787.377654077 and parameters: {'n_estimators': 114, 'learning_rate': 0.07994707940129563, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.8460668265816481, 'max_features': 'sqrt'}. Best is trial 2 with value: -10912787.377654077.\n",
      "[I 2025-04-04 20:04:24,834] Trial 0 finished with value: -11450856.46951915 and parameters: {'n_estimators': 159, 'learning_rate': 0.01568487025430545, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.702887773434642, 'max_features': 'log2'}. Best is trial 2 with value: -10912787.377654077.\n",
      "[I 2025-04-04 20:04:25,098] Trial 3 finished with value: -12921520.811848404 and parameters: {'n_estimators': 176, 'learning_rate': 0.012618958916527796, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.870327380437836, 'max_features': 'sqrt'}. Best is trial 2 with value: -10912787.377654077.\n",
      "[I 2025-04-04 20:04:26,743] Trial 1 finished with value: -10427017.263796855 and parameters: {'n_estimators': 196, 'learning_rate': 0.015654202230059235, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.935964001953831, 'max_features': 'log2'}. Best is trial 1 with value: -10427017.263796855.\n",
      "[I 2025-04-04 20:04:28,565] Trial 5 finished with value: -12278597.787277391 and parameters: {'n_estimators': 185, 'learning_rate': 0.017911711428971383, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8213381998204419, 'max_features': 'log2'}. Best is trial 1 with value: -10427017.263796855.\n",
      "[I 2025-04-04 20:04:34,741] Trial 8 finished with value: -11209108.60808414 and parameters: {'n_estimators': 326, 'learning_rate': 0.09156339685171697, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.850220552973039, 'max_features': 'log2'}. Best is trial 1 with value: -10427017.263796855.\n",
      "[I 2025-04-04 20:04:36,090] Trial 7 finished with value: -10827393.26609747 and parameters: {'n_estimators': 406, 'learning_rate': 0.0732541021790653, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7708461141733056, 'max_features': 'sqrt'}. Best is trial 1 with value: -10427017.263796855.\n",
      "[I 2025-04-04 20:04:36,620] Trial 4 finished with value: -10112618.286388543 and parameters: {'n_estimators': 466, 'learning_rate': 0.02215517564855081, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.7555198506360794, 'max_features': 'log2'}. Best is trial 4 with value: -10112618.286388543.\n",
      "[I 2025-04-04 20:04:39,400] Trial 6 finished with value: -10507173.474317254 and parameters: {'n_estimators': 487, 'learning_rate': 0.0906989606784456, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.9278997791268097, 'max_features': 'log2'}. Best is trial 4 with value: -10112618.286388543.\n",
      "[I 2025-04-04 20:04:42,543] Trial 9 finished with value: -10913066.989041049 and parameters: {'n_estimators': 416, 'learning_rate': 0.052750042123033705, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.7506843177511976, 'max_features': 'sqrt'}. Best is trial 4 with value: -10112618.286388543.\n",
      "[I 2025-04-04 20:04:43,472] Trial 10 finished with value: -10430435.496974327 and parameters: {'n_estimators': 293, 'learning_rate': 0.05234711418337435, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.9791599340856901, 'max_features': 'sqrt'}. Best is trial 4 with value: -10112618.286388543.\n",
      "[I 2025-04-04 20:04:43,667] Trial 12 finished with value: -14784335.71977078 and parameters: {'n_estimators': 209, 'learning_rate': 0.010085010789843045, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.808378029865997, 'max_features': 'log2'}. Best is trial 4 with value: -10112618.286388543.\n",
      "[I 2025-04-04 20:04:49,243] Trial 11 finished with value: -10255255.75455521 and parameters: {'n_estimators': 429, 'learning_rate': 0.02492441057080751, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.8814896329197657, 'max_features': 'log2'}. Best is trial 4 with value: -10112618.286388543.\n",
      "[I 2025-04-04 20:04:50,656] Trial 13 finished with value: -9983974.986712333 and parameters: {'n_estimators': 289, 'learning_rate': 0.03341698722349975, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.9912806082782379, 'max_features': 'log2'}. Best is trial 13 with value: -9983974.986712333.\n",
      "[I 2025-04-04 20:04:50,782] Trial 14 finished with value: -9986746.785710612 and parameters: {'n_estimators': 257, 'learning_rate': 0.024376473776371067, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 0.9228151310262026, 'max_features': 'log2'}. Best is trial 13 with value: -9983974.986712333.\n",
      "[I 2025-04-04 20:04:51,516] Trial 15 finished with value: -9846153.483081637 and parameters: {'n_estimators': 274, 'learning_rate': 0.02480425883601079, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 0.9144026078900276, 'max_features': 'log2'}. Best is trial 15 with value: -9846153.483081637.\n",
      "[I 2025-04-04 20:04:57,463] Trial 17 finished with value: -9944224.84591124 and parameters: {'n_estimators': 278, 'learning_rate': 0.029185516736949593, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.9890470090461221, 'max_features': 'log2'}. Best is trial 15 with value: -9846153.483081637.\n",
      "[I 2025-04-04 20:04:57,785] Trial 18 finished with value: -9977129.012718048 and parameters: {'n_estimators': 280, 'learning_rate': 0.035053765914426355, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 0.9982931405712118, 'max_features': 'log2'}. Best is trial 15 with value: -9846153.483081637.\n",
      "[I 2025-04-04 20:05:00,174] Trial 19 finished with value: -10049684.581970815 and parameters: {'n_estimators': 360, 'learning_rate': 0.038328437292917364, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.9899484786491105, 'max_features': 'log2'}. Best is trial 15 with value: -9846153.483081637.\n",
      "[I 2025-04-04 20:05:02,222] Trial 16 finished with value: -9793388.595389893 and parameters: {'n_estimators': 489, 'learning_rate': 0.026716324774950354, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.904389658423455, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:06,301] Trial 20 finished with value: -10195876.232016826 and parameters: {'n_estimators': 351, 'learning_rate': 0.03543960258143651, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9631506625082396, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:06,453] Trial 21 finished with value: -9905448.331378005 and parameters: {'n_estimators': 352, 'learning_rate': 0.04023076454008672, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.949757052797286, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:08,816] Trial 22 finished with value: -10225537.596035665 and parameters: {'n_estimators': 347, 'learning_rate': 0.043279127373377205, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.9549211207966144, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:10,866] Trial 23 finished with value: -10327726.747620305 and parameters: {'n_estimators': 355, 'learning_rate': 0.044279397730801945, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8995057168348206, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:12,121] Trial 24 finished with value: -10092549.358946767 and parameters: {'n_estimators': 235, 'learning_rate': 0.021008344899929875, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.9029410536604572, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:12,804] Trial 25 finished with value: -10058084.84845694 and parameters: {'n_estimators': 239, 'learning_rate': 0.05213392027206611, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8970547953804344, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:15,374] Trial 26 finished with value: -10003441.977997864 and parameters: {'n_estimators': 239, 'learning_rate': 0.02025527401510933, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.9009239916048358, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:17,414] Trial 27 finished with value: -9898435.40787209 and parameters: {'n_estimators': 244, 'learning_rate': 0.027718755624059028, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.9061942863000537, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:22,013] Trial 28 finished with value: -9930945.430625472 and parameters: {'n_estimators': 387, 'learning_rate': 0.028569871227141778, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.9506553572347364, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:22,799] Trial 29 finished with value: -10256814.912986431 and parameters: {'n_estimators': 388, 'learning_rate': 0.028044310091315847, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.9534524137354526, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:25,500] Trial 32 finished with value: -12473286.621196553 and parameters: {'n_estimators': 128, 'learning_rate': 0.015419718071435046, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.874974452851, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:26,082] Trial 30 finished with value: -9841772.444885185 and parameters: {'n_estimators': 383, 'learning_rate': 0.02836251270106338, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9355743674162414, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:28,450] Trial 31 finished with value: -9896925.035744349 and parameters: {'n_estimators': 389, 'learning_rate': 0.0278248970263374, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.8725093959152194, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:30,830] Trial 33 finished with value: -10281199.340266448 and parameters: {'n_estimators': 316, 'learning_rate': 0.015503788076045027, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.8554313977351021, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:34,040] Trial 34 finished with value: -9926394.82127983 and parameters: {'n_estimators': 315, 'learning_rate': 0.02514956780844524, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.9299827602371779, 'max_features': 'log2'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:34,866] Trial 35 finished with value: -10057014.147480482 and parameters: {'n_estimators': 319, 'learning_rate': 0.017651726559798183, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.9295492810998541, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:42,176] Trial 36 finished with value: -10029660.176622326 and parameters: {'n_estimators': 499, 'learning_rate': 0.01804944829786443, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.8524704524369555, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:43,679] Trial 37 finished with value: -9884581.443412185 and parameters: {'n_estimators': 450, 'learning_rate': 0.017972359285175845, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9240192584839179, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:44,471] Trial 39 finished with value: -10385666.807502728 and parameters: {'n_estimators': 459, 'learning_rate': 0.01890423236595022, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.8102385197123497, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:47,097] Trial 38 finished with value: -10117158.619765416 and parameters: {'n_estimators': 453, 'learning_rate': 0.018927151985018285, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.8198988777790307, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:52,104] Trial 40 finished with value: -10217206.519446466 and parameters: {'n_estimators': 454, 'learning_rate': 0.03131931753068566, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.881703517835763, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:53,424] Trial 41 finished with value: -10414707.128896117 and parameters: {'n_estimators': 447, 'learning_rate': 0.012682618236234174, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.8215217575194285, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:54,226] Trial 42 finished with value: -10420803.14998027 and parameters: {'n_estimators': 450, 'learning_rate': 0.012947849811501856, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.9153632702199924, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:05:58,351] Trial 43 finished with value: -10106417.048384469 and parameters: {'n_estimators': 437, 'learning_rate': 0.012070652352017533, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.9147554864687482, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:06:03,868] Trial 44 finished with value: -10455331.304792099 and parameters: {'n_estimators': 437, 'learning_rate': 0.022922978561721506, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.9210048905182289, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:06:06,116] Trial 45 finished with value: -10103905.103022438 and parameters: {'n_estimators': 481, 'learning_rate': 0.023835472111674492, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.9163826243431747, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:06:06,310] Trial 46 finished with value: -10007748.546870109 and parameters: {'n_estimators': 482, 'learning_rate': 0.02151258551176164, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9402384156602613, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:06:09,359] Trial 47 finished with value: -9969079.439629873 and parameters: {'n_estimators': 480, 'learning_rate': 0.02343319204901232, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9411792679070559, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:06:11,934] Trial 48 finished with value: -10286272.355889376 and parameters: {'n_estimators': 471, 'learning_rate': 0.02563610616410476, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.8657156158017739, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n",
      "[I 2025-04-04 20:06:12,135] Trial 49 finished with value: -9950417.025316406 and parameters: {'n_estimators': 402, 'learning_rate': 0.026456709295258674, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9721121299889856, 'max_features': 'sqrt'}. Best is trial 16 with value: -9793388.595389893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GBR Params: {'n_estimators': 489, 'learning_rate': 0.026716324774950354, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.904389658423455, 'max_features': 'log2'}\n",
      "Best GBR Score: -9793388.595389893\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization on Gradient Boosting\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective_gbr(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "    }\n",
    "\n",
    "    model = GradientBoostingRegressor(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    return score\n",
    "\n",
    "study_gbr = optuna.create_study(direction='maximize')  # maximize negative MSE = minimize MSE\n",
    "study_gbr.optimize(objective_gbr, n_trials=50, n_jobs=-1)\n",
    "\n",
    "print(\"Best GBR Params:\", study_gbr.best_params)\n",
    "print(\"Best GBR Score:\", study_gbr.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1432.3006\n",
      "R Score: 0.8727\n"
     ]
    }
   ],
   "source": [
    "# Use best parameters from Optuna study\n",
    "best_gbr_params = study_gbr.best_params\n",
    "\n",
    "# Train model using best parameters\n",
    "gbr_best_model = GradientBoostingRegressor(**best_gbr_params)\n",
    "gbr_best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = gbr_best_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae, 4))\n",
    "print(\"R Score:\", round(r2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-04-07 13:35:27,734]\u001b[0m A new study created in memory with name: no-name-5a28702e-775f-4d3b-ad15-257623cde681\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:35:38,503]\u001b[0m Trial 0 finished with value: -10877592.825608071 and parameters: {'n_estimators': 287, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: -10877592.825608071.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:35:51,004]\u001b[0m Trial 3 finished with value: -12887415.013838667 and parameters: {'n_estimators': 261, 'criterion': 'absolute_error', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 0 with value: -10877592.825608071.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:01,534]\u001b[0m Trial 5 finished with value: -10895255.0580046 and parameters: {'n_estimators': 319, 'criterion': 'squared_error', 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: -10877592.825608071.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:05,240]\u001b[0m Trial 1 finished with value: -12043554.451429188 and parameters: {'n_estimators': 369, 'criterion': 'absolute_error', 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 0 with value: -10877592.825608071.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:15,783]\u001b[0m Trial 6 finished with value: -9397552.58471007 and parameters: {'n_estimators': 297, 'criterion': 'squared_error', 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:16,665]\u001b[0m Trial 4 finished with value: -11885235.494451236 and parameters: {'n_estimators': 379, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:18,171]\u001b[0m Trial 2 finished with value: -11833030.072006173 and parameters: {'n_estimators': 482, 'criterion': 'absolute_error', 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:29,013]\u001b[0m Trial 10 finished with value: -10839717.096579783 and parameters: {'n_estimators': 354, 'criterion': 'friedman_mse', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:39,913]\u001b[0m Trial 11 finished with value: -11986003.834907543 and parameters: {'n_estimators': 406, 'criterion': 'friedman_mse', 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:42,075]\u001b[0m Trial 7 finished with value: -12990585.748034637 and parameters: {'n_estimators': 432, 'criterion': 'absolute_error', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:43,284]\u001b[0m Trial 8 finished with value: -11306597.288908053 and parameters: {'n_estimators': 259, 'criterion': 'absolute_error', 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 6 with value: -9397552.58471007.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:49,511]\u001b[0m Trial 13 finished with value: -9366740.341094097 and parameters: {'n_estimators': 155, 'criterion': 'squared_error', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 13 with value: -9366740.341094097.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:51,309]\u001b[0m Trial 12 finished with value: -9140728.942324394 and parameters: {'n_estimators': 225, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:51,530]\u001b[0m Trial 14 finished with value: -9677582.697973333 and parameters: {'n_estimators': 138, 'criterion': 'squared_error', 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:57,158]\u001b[0m Trial 15 finished with value: -9316034.32958379 and parameters: {'n_estimators': 140, 'criterion': 'squared_error', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:36:59,159]\u001b[0m Trial 16 finished with value: -9228270.710198212 and parameters: {'n_estimators': 150, 'criterion': 'squared_error', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:00,541]\u001b[0m Trial 17 finished with value: -9254894.26604062 and parameters: {'n_estimators': 181, 'criterion': 'friedman_mse', 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:06,699]\u001b[0m Trial 18 finished with value: -9150299.413552683 and parameters: {'n_estimators': 192, 'criterion': 'friedman_mse', 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:09,332]\u001b[0m Trial 19 finished with value: -9241747.861012463 and parameters: {'n_estimators': 203, 'criterion': 'friedman_mse', 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:09,506]\u001b[0m Trial 9 finished with value: -9346971.597693514 and parameters: {'n_estimators': 208, 'criterion': 'absolute_error', 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:11,000]\u001b[0m Trial 20 finished with value: -9184695.08788233 and parameters: {'n_estimators': 207, 'criterion': 'friedman_mse', 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:15,653]\u001b[0m Trial 23 finished with value: -9247455.750840543 and parameters: {'n_estimators': 101, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 12 with value: -9140728.942324394.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:17,998]\u001b[0m Trial 24 finished with value: -9030496.95185503 and parameters: {'n_estimators': 105, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:19,960]\u001b[0m Trial 21 finished with value: -9041650.012397451 and parameters: {'n_estimators': 214, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:23,189]\u001b[0m Trial 22 finished with value: -9172634.012169514 and parameters: {'n_estimators': 220, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:28,860]\u001b[0m Trial 28 finished with value: -9206258.057623675 and parameters: {'n_estimators': 100, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:29,831]\u001b[0m Trial 25 finished with value: -9250203.707440894 and parameters: {'n_estimators': 238, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:33,397]\u001b[0m Trial 26 finished with value: -9075681.38965061 and parameters: {'n_estimators': 257, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:35,271]\u001b[0m Trial 27 finished with value: -9041104.75003222 and parameters: {'n_estimators': 257, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:39,933]\u001b[0m Trial 29 finished with value: -11071961.46052505 and parameters: {'n_estimators': 254, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:44,651]\u001b[0m Trial 30 finished with value: -11021164.728872951 and parameters: {'n_estimators': 326, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:48,709]\u001b[0m Trial 31 finished with value: -11194183.384330455 and parameters: {'n_estimators': 328, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:51,193]\u001b[0m Trial 32 finished with value: -11191390.216852058 and parameters: {'n_estimators': 328, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:54,223]\u001b[0m Trial 33 finished with value: -11004498.553223576 and parameters: {'n_estimators': 312, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:37:59,385]\u001b[0m Trial 35 finished with value: -9141734.596354911 and parameters: {'n_estimators': 173, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:02,718]\u001b[0m Trial 34 finished with value: -9158168.219559936 and parameters: {'n_estimators': 285, 'criterion': 'friedman_mse', 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:07,329]\u001b[0m Trial 36 finished with value: -9236248.891526513 and parameters: {'n_estimators': 277, 'criterion': 'friedman_mse', 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:10,337]\u001b[0m Trial 37 finished with value: -9166341.621022085 and parameters: {'n_estimators': 281, 'criterion': 'friedman_mse', 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:16,601]\u001b[0m Trial 38 finished with value: -9082198.728552233 and parameters: {'n_estimators': 290, 'criterion': 'friedman_mse', 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:19,960]\u001b[0m Trial 41 finished with value: -11365532.149052558 and parameters: {'n_estimators': 237, 'criterion': 'friedman_mse', 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:20,183]\u001b[0m Trial 39 finished with value: -9122953.116240408 and parameters: {'n_estimators': 279, 'criterion': 'friedman_mse', 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:21,703]\u001b[0m Trial 40 finished with value: -9154838.417048443 and parameters: {'n_estimators': 237, 'criterion': 'friedman_mse', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:35,400]\u001b[0m Trial 42 finished with value: -11396302.98317902 and parameters: {'n_estimators': 239, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 24 with value: -9030496.95185503.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:38:48,327]\u001b[0m Trial 46 finished with value: -9024219.029565306 and parameters: {'n_estimators': 348, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 46 with value: -9024219.029565306.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:39:18,101]\u001b[0m Trial 43 finished with value: -9677229.39066324 and parameters: {'n_estimators': 361, 'criterion': 'absolute_error', 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 46 with value: -9024219.029565306.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:39:19,899]\u001b[0m Trial 44 finished with value: -9611025.477200285 and parameters: {'n_estimators': 357, 'criterion': 'absolute_error', 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 46 with value: -9024219.029565306.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:39:22,578]\u001b[0m Trial 45 finished with value: -9553007.555512799 and parameters: {'n_estimators': 364, 'criterion': 'absolute_error', 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 46 with value: -9024219.029565306.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:39:37,178]\u001b[0m Trial 49 finished with value: -9002651.313008616 and parameters: {'n_estimators': 390, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 49 with value: -9002651.313008616.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:39:37,741]\u001b[0m Trial 48 finished with value: -9133382.274717811 and parameters: {'n_estimators': 475, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 49 with value: -9002651.313008616.\u001b[0m\n",
      "\u001b[32m[I 2025-04-07 13:39:46,593]\u001b[0m Trial 47 finished with value: -9636801.659463594 and parameters: {'n_estimators': 384, 'criterion': 'absolute_error', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 49 with value: -9002651.313008616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'n_estimators': 390, 'criterion': 'friedman_mse', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}\n",
      "Best RF Score: -9002651.313008616\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization on Random Forest\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['squared_error', 'absolute_error', 'friedman_mse']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    return score\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, n_jobs=-1)\n",
    "\n",
    "print(\"Best RF Params:\", study_rf.best_params)\n",
    "print(\"Best RF Score:\", study_rf.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Absolute Error (MAE): 1014.5223\n",
      "Random Forest - R Score: 0.9032\n"
     ]
    }
   ],
   "source": [
    "# Use best parameters from Optuna study\n",
    "best_rf_params = study_rf.best_params\n",
    "\n",
    "# Train model using best parameters\n",
    "rf_best_model = RandomForestRegressor(**best_rf_params)\n",
    "rf_best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf_best_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest - Mean Absolute Error (MAE):\", round(mae_rf, 4))\n",
    "print(\"Random Forest - R Score:\", round(r2_rf, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Saving the trained Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.75264228e-01, 9.21055836e-04, 5.54416133e-03, 1.05622642e-01,\n",
       "       3.85730690e-02, 1.50950809e-02, 7.20295031e-02, 4.10028934e-04,\n",
       "       2.31847508e-02, 3.13895608e-02, 3.19659188e-02])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_rf_model.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_best_model, 'new_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Identifying feature importances from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Importance\n",
      "0                       Age    0.675264\n",
      "3            AnyTransplants    0.105623\n",
      "6                    Weight    0.072030\n",
      "4        AnyChronicDiseases    0.038573\n",
      "10                      BMI    0.031966\n",
      "9    NumberOfMajorSurgeries    0.031390\n",
      "8   HistoryOfCancerInFamily    0.023185\n",
      "5                    Height    0.015095\n",
      "2     BloodPressureProblems    0.005544\n",
      "1                  Diabetes    0.000921\n",
      "7            KnownAllergies    0.000410\n"
     ]
    }
   ],
   "source": [
    "importances = rf_best_model.feature_importances_\n",
    "feature_names = rf_best_model.feature_names_in_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env_213",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
